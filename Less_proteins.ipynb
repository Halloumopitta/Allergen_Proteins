{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c91bcfd0",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "\n",
    "1. Initially \"criterion = nn.CrossEntropyLoss()\" that expects torch.long numbers to be parsed, but our 2nd mapping uses float numbers instead so now a Binary cross entropy function is used together with a sigmoid function to flatten the outputs between 0 and 1\n",
    "2. Our BCE criterion also requires a sigmoid layer at the output to squash the output between 0 and 1 and also the unsqueeze(1) command so that the shape of our data and targets match the output (e.g torch.Size([ batch_size]) becomes              torch.Size([ batch_size,1])  )  reference: https://medium.com/analytics-vidhya/simple-neural-network-with-bceloss-for-binary-classification-for-a-custom-dataset-8d5c69ffffee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe497c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, re\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim  \n",
    "import torchvision.transforms as transforms  \n",
    "import torchvision\n",
    "from torch.utils.data import (Dataset,DataLoader)\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b99c3d",
   "metadata": {},
   "source": [
    "# Allergen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5753e377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total proteins left: 1654\n",
      "Minimum length: 5\n",
      "Maximum length: 498\n",
      "Mean: 231.8186215235792\n",
      "Median: 211.0\n",
      "Mode: 134\n"
     ]
    }
   ],
   "source": [
    "#Define a class to  filter out  the unwanted proteins\n",
    "def filter_fasta(input_file, output_file, min_length, max_length):\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    filtered_proteins = []\n",
    "    filtered_lengths = []\n",
    "\n",
    "    current_protein = None\n",
    "    current_sequence = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith('>'):\n",
    "            if current_protein is not None:\n",
    "                sequence = ''.join(current_sequence)\n",
    "                sequence_length = len(sequence)\n",
    "                if min_length <= sequence_length <= max_length:\n",
    "                    filtered_proteins.append(current_protein + '\\n' + sequence)\n",
    "                    filtered_lengths.append(sequence_length)\n",
    "            current_protein = line.strip()\n",
    "            current_sequence = []\n",
    "        else:\n",
    "            current_sequence.append(line.strip())\n",
    "\n",
    "    # Check the last protein after the loop ends\n",
    "    if current_protein is not None:\n",
    "        sequence = ''.join(current_sequence)\n",
    "        sequence_length = len(sequence)\n",
    "        if min_length <= sequence_length <= max_length:\n",
    "            filtered_proteins.append(current_protein + '\\n' + sequence)\n",
    "            filtered_lengths.append(sequence_length)\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('\\n'.join(filtered_proteins))\n",
    "\n",
    "    # Calculate statistics\n",
    "    total_proteins = len(filtered_proteins)\n",
    "    min_length = min(filtered_lengths)\n",
    "    max_length = max(filtered_lengths)\n",
    "    mean = np.mean(filtered_lengths)\n",
    "    median= np.median(filtered_lengths)\n",
    "    mode = stats.mode(filtered_lengths)\n",
    "\n",
    "    # Plot distribution\n",
    "    plt.hist(filtered_lengths, bins=50)\n",
    "    plt.xlabel('Protein length')\n",
    "    plt.ylabel('Number of proteins')\n",
    "    plt.title('Histogram of filtered allergen proteins')\n",
    "    plt.show()\n",
    "\n",
    "    return total_proteins, min_length, max_length, mean, median, mode\n",
    "\n",
    "# Usage\n",
    "total, minimum, maximum,mean,median,mode = filter_fasta('Allergen_Proteins.fasta', 'Filtered_Allergen_Proteins.fasta', 1, 500)\n",
    "print(\"Total proteins left:\", total)\n",
    "print(\"Minimum length:\", minimum)\n",
    "print(\"Maximum length:\", maximum)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Mode:\", mode[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4257a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sequence(sequence, mapping):\n",
    "    map = [mapping[aa] for aa in sequence if aa in mapping]\n",
    "    return np.array(map)\n",
    "\n",
    "def map_fasta(input_file, mapping):\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    mapped_sequences = []\n",
    "\n",
    "    current_protein_id = None\n",
    "    current_sequence = ''\n",
    "    for line in lines:\n",
    "        if line.startswith('>'):\n",
    "            if current_protein_id and current_sequence:\n",
    "                mapped_sequence = map_sequence(current_sequence, mapping)\n",
    "                mapped_sequences.append((current_protein_id, mapped_sequence))\n",
    "            current_protein_id = line.strip()[1:]\n",
    "            current_sequence = ''\n",
    "        else:\n",
    "            current_sequence += line.strip()\n",
    "\n",
    "    # Process the last protein sequence\n",
    "    if current_protein_id and current_sequence:\n",
    "        mapped_sequence = map_sequence(current_sequence, mapping)\n",
    "        mapped_sequences.append((current_protein_id, mapped_sequence))\n",
    "\n",
    "    return mapped_sequences\n",
    "\n",
    "# Mapping of amino acids to numbers\n",
    "mapping = {\n",
    "    'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10,\n",
    "    'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19,\n",
    "    'Y': 20, 'X': 0, 'Z': 0\n",
    "}\n",
    "\n",
    "# Input FASTA file path\n",
    "input_file = 'Filtered_Allergen_Proteins.fasta'\n",
    "\n",
    "\n",
    "mapped_sequences = map_fasta(input_file, mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d96fce5",
   "metadata": {},
   "source": [
    "# Unkwown proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b539035a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 5000 proteins and saved them as 'Reduced_NOT_Allergen_Proteins.fasta'.\n"
     ]
    }
   ],
   "source": [
    "input_file = 'NOT_Allergen_Proteins.fasta'\n",
    "output_file = 'Reduced_NOT_Allergen_Proteins.fasta'\n",
    "selected = 5000\n",
    "\n",
    "\n",
    "proteins = list(SeqIO.parse(input_file, 'fasta'))\n",
    "\n",
    "\n",
    "selected_proteins = random.sample(proteins, selected)\n",
    "\n",
    "# Write the selected protein records to the output file\n",
    "SeqIO.write(selected_proteins, output_file, 'fasta')\n",
    "\n",
    "print(f\"Selected {selected} proteins and saved them as '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe0f4d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total proteins left: 4007\n",
      "Minimum length: 3\n",
      "Maximum length: 500\n",
      "Mean: 254.67431994010482\n",
      "Median: 247.0\n",
      "Mode: 198\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "total, minimum, maximum, mean,median,mode = filter_fasta('Reduced_NOT_Allergen_Proteins.fasta', 'Filtered_NOT_Allergen_Proteins.fasta', 1,500)\n",
    "print(\"Total proteins left:\", total)\n",
    "print(\"Minimum length:\", minimum)\n",
    "print(\"Maximum length:\", maximum)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Mode:\", mode[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da638d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert amino acid sequences to numbers\n",
    "def map_sequence(sequence, mapping):\n",
    "    map = [mapping[aa] for aa in sequence if aa in mapping]\n",
    "    return np.array(map)\n",
    "\n",
    "def map_fasta(input_file, mapping):\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    mapped_sequences = []\n",
    "\n",
    "    current_protein_id = None\n",
    "    current_sequence = ''\n",
    "    for line in lines:\n",
    "        if line.startswith('>'):\n",
    "            if current_protein_id and current_sequence:\n",
    "                mapped_sequence = map_sequence(current_sequence, mapping)\n",
    "                mapped_sequences.append((current_protein_id, mapped_sequence))\n",
    "            current_protein_id = line.strip()[1:]\n",
    "            current_sequence = ''\n",
    "        else:\n",
    "            current_sequence += line.strip()\n",
    "\n",
    "    # Process the last protein sequence\n",
    "    if current_protein_id and current_sequence:\n",
    "        mapped_sequence = map_sequence(current_sequence, mapping)\n",
    "        mapped_sequences.append((current_protein_id, mapped_sequence))\n",
    "\n",
    "    return mapped_sequences\n",
    "\n",
    "# Mapping of amino acids to numbers\n",
    "mapping = {\n",
    "    'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10,\n",
    "    'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19,\n",
    "    'Y': 20, 'X': 0 , 'U': 0, 'B': 0, 'J': 0, 'O': 0,'Z':0\n",
    "}\n",
    "\n",
    "# Input FASTA file path\n",
    "input_file = 'Filtered_NOT_Allergen_Proteins.fasta'\n",
    "\n",
    "\n",
    "mapped_sequences = map_fasta(input_file, mapping)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c9d5c",
   "metadata": {},
   "source": [
    "# Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9dca741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of proteins: 8007\n",
      "Total number of allergen proteins: 4000\n",
      "Total number of non allergen proteins: 4007\n",
      "Max length: 500\n",
      "First 5 proteins:\n",
      "Label: 0\n",
      "Sequence: MPFLVALSGIISGVRDHSMTVRLDQQTRQRLQDIVKGGYRSANAAIVDAINKRWEALHDEQLDAAYAAAIHDNPAYPYESEAERSAARARRNARQQRSAQXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "\n",
      "Label: 1\n",
      "Sequence: MVKEFNTQTELSVRLEALWAVLSKDFITVVPKVLPHIVKDVQLIEGDGGVGTILIFNFLPEVSPSYQREEITEFDESSHEIGLQVIEGGYLSQGLSYYKTTFKLSEIEEDKTLVNVKISYDHDSDIEEKVTPTKTSQSTLMYLRRLERYLSNGSAXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "\n",
      "Label: 0\n",
      "Sequence: MTLLTRIKTETILLESDIKELIDILISPSIGTDIKYELLSSYSEREIQQQELTYIVRSLINTMYPHQPCYEGAMCVCGTGGDKSNSFNISTTVAFVVASAGVKVIKHGNKSITSNSGSTDLLNQMNIQTTTVDDTPNQLNEKDLVFIGATESYPIMKYMQPVRKMIGKPTILNLVGPLINPYHLTYQMVGVFDPTKLKLVAKTIKDLGRKRAIVLHGANGMDEATLSGDNLIYELTEDGEIKNYTLNATDYGLKHAPNSDFKGGSPEENLAISLNILNGKDQSSRRDVVLLNAGLSLYVAEKVDTIAEGIELATTLIDNGEALEKYHQMRGEXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "\n",
      "Label: 1\n",
      "Sequence: MEIKHLLFLVAAACLLPMLSMKKKSARDQFNKLVTDLPNVQEEIVNIHNALRRRVVPPASNMLKMSWSEEAAQNARIFSKYCDMTESNPLERRLPNTFCGENMHMTSYPVSWSSVIGVWYSESTSFKHGEWTTTDDDITTDHYTQIVWATSYLIGCAIASCRQQGSPRYLYVCHYCHEGNDPETKNEPYKTGVPCEACPSNCEDKLCTNPCIYYDEYFDCDIQVHYLGCNHSTTILFCKATCLCDTEIKXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "\n",
      "Label: 0\n",
      "Sequence: MMLLLPLIIVLMMKLSDARTHSLRYFRLGISEPGYGIPEFISAGYVDSHPITMYNSVSQLKEPRALWMEENLAPDHWERYTQLLRGWQQAFKVELKQLQHHYNHSGFHTYQRMIGCELLEDGSITGFLQYAYDGQDFLIFNKDTLSWMAMDNVADIIRRVWEANRHELQYQKNWLEEECIAWLKRFLEYGKDALQRTEPPKVRVNHKETFPGITTLYCRAYGFYPPEISINWMKNGEEIFQDTDYGGILPSGDGTYQTWVSVELDPQNGDIYSCHVEHGGVHMVLQGFQESETILLVVKAVGFIVLAIALAGVGILAWRKRPRGKNKVICLSTPEHXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sequence_padding(sequences, max_length):\n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        padding_length = max_length - len(seq)\n",
    "        padded_seq = seq + \"X\" * padding_length  # Padding with a special token, \"X\"\n",
    "        padded_sequences.append(padded_seq)\n",
    "    return padded_sequences\n",
    "\n",
    "allergen_sequences = []\n",
    "allergen_headers = []\n",
    "\n",
    "with open(\"Filtered_Allergen_Proteins.fasta\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    if line.startswith(\">\"):\n",
    "        allergen_headers.append(line.strip())\n",
    "    else:\n",
    "        allergen_sequences.append(line.strip())\n",
    "        \n",
    "# Randomly select allergen proteins to increase the count up to 5000\n",
    "while len(allergen_sequences) < 4000:\n",
    "    random_protein = random.choice(allergen_sequences)\n",
    "    allergen_sequences.append(random_protein)\n",
    "\n",
    "non_allergen_sequences = []\n",
    "non_allergen_headers = []\n",
    "\n",
    "with open(\"Filtered_NOT_Allergen_Proteins.fasta\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    if line.startswith(\">\"):\n",
    "        non_allergen_headers.append(line.strip())\n",
    "    else:\n",
    "        non_allergen_sequences.append(line.strip())\n",
    "\n",
    "# Step 2: Create a merged dataset\n",
    "merged_sequences = allergen_sequences + non_allergen_sequences\n",
    "merged_labels = [1] * len(allergen_sequences) + [0] * len(non_allergen_sequences)\n",
    "\n",
    "# Shuffle the protein order\n",
    "merged_data = list(zip(merged_sequences, merged_labels))\n",
    "random.shuffle(merged_data)\n",
    "merged_sequences, merged_labels = zip(*merged_data)\n",
    "\n",
    "# Step 3: Determine the maximum sequence length for padding\n",
    "max_length = max(len(seq) for seq in merged_sequences)\n",
    "\n",
    "# Step 4: Apply sequence padding\n",
    "padded_sequences = sequence_padding(merged_sequences, max_length)\n",
    "\n",
    "# Step 5: Save the merged dataset with padded sequences\n",
    "with open(\"Proteins.fasta\", \"w\") as file:\n",
    "    for i in range(len(padded_sequences)):\n",
    "        file.write(\"> Label:\" + str(merged_labels[i]) + \"\\n\")\n",
    "        file.write(padded_sequences[i] + \"\\n\")\n",
    "\n",
    "# Print the total number of proteins\n",
    "total_proteins = len(padded_sequences)\n",
    "print(\"Total number of proteins:\", total_proteins)\n",
    "\n",
    "\n",
    "label_1 = sum(label == 1 for label in merged_labels)\n",
    "label_0 = sum(label == 0 for label in merged_labels)\n",
    "\n",
    "print(\"Total number of allergen proteins:\", label_1)\n",
    "print(\"Total number of non allergen proteins:\", label_0)\n",
    "print(\"Max length:\",max_length)\n",
    "# Print the first 5 proteins\n",
    "print(\"First 5 proteins:\")\n",
    "for i in range(5):\n",
    "    print(\"Label:\", merged_labels[i])\n",
    "    print(\"Sequence:\", padded_sequences[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29a2f981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 1: 0\n",
      "Sequence 1: MPFLVALSGIISGVRDHSMTVRLDQQTRQRLQDIVKGGYRSANAAIVDAINKRWEALHDEQLDAAYAAAIHDNPAYPYESEAERSAARARRNARQQRSAQXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "\n",
      "Total number of sequences: 8007\n",
      "First mapped sequence: [-3.66, 0.75, -4.65, -4.68, -3.5, -0.21, -4.68, 1.74, 0, -4.81, -4.81, 1.74, 0, -3.5, 2.11, 1.36, -1.23, 1.74, -3.66, 0.78, -3.5, 2.11, -4.68, 1.36, 1.52, 1.52, 0.78, 2.11, 1.52, 2.11, -4.68, 1.52, 1.36, -4.81, -3.5, 3.88, 0, 0, -1.01, 2.11, 1.74, -0.21, 0.96, -0.21, -0.21, -4.81, -3.5, 1.36, -0.21, -4.81, 0.96, 3.88, 2.11, -3.32, 2.3, -0.21, -4.68, -1.23, 1.36, 2.3, 1.52, -4.68, 1.36, -0.21, -0.21, -1.01, -0.21, -0.21, -0.21, -4.81, -1.23, 1.36, 0.96, 0.75, -0.21, -1.01, 0.75, -1.01, 2.3, 1.74, 2.3, -0.21, 2.3, 2.11, 1.74, -0.21, -0.21, 2.11, -0.21, 2.11, 2.11, 0.96, -0.21, 2.11, 1.52, 1.52, 2.11, 1.74, -0.21, 1.52, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Length of each sequence: 500\n",
      "8007\n",
      "Numeric sequences and labels saved to Mapped.fasta\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################\n",
    "\n",
    "#Create a class that takes the encoded sequences and labels to split later for train,val and test\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        \n",
    "        sequence_tensor = torch.tensor(sequence, dtype=torch.float)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "        return sequence_tensor, label_tensor\n",
    "\n",
    "    \n",
    "################################################################################################################################\n",
    "\n",
    "################################################################################################################################\n",
    "# Load the merged dataset with padded sequences and verify it works by printing the first sequence\n",
    "merged_sequences = []\n",
    "merged_labels = []\n",
    "\n",
    "with open(\"Proteins.fasta\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for i in range(0, len(lines),2):\n",
    "    sequence = lines[i+1].strip() #check every odd line and strip any whitespace\n",
    "    label = int(lines[i].split(\":\")[1]) #check every even line\n",
    "    merged_sequences.append(sequence)\n",
    "    merged_labels.append(label)\n",
    "    \n",
    "for i in range(1):\n",
    "    print(f\"Label {i+1}: {merged_labels[i]}\")\n",
    "    print(f\"Sequence {i+1}: {merged_sequences[i]}\")\n",
    "    print()\n",
    "\n",
    "################################################################################################################################\n",
    "#Map sequences to numbers again and save the file\n",
    "mapping= {\n",
    "    'A': -0.21, 'C': -6.04, 'D': 1.36, 'E': 2.3, 'F': -4.65, 'G': 0, 'H': -1.23,\n",
    "    'I': -4.81, 'K': 3.88, 'L': -4.68, 'M': -3.66, 'N': 0.96, 'P': 0.75, 'Q': 1.52,\n",
    "    'R': 2.11, 'S': 1.74, 'T': 0.78, 'V': -3.5, 'W': -3.32, 'Y': -1.01,\n",
    "    'X': 0, 'U': 0, 'B': 0, 'J': 0, 'O': 0, 'Z': 0\n",
    "}\n",
    "\n",
    "# Convert all sequences to numerical arrays using the custom mapping\n",
    "# Assuming you have already loaded the merged_sequences list and defined the custom mapping\n",
    "\n",
    "# Convert all sequences to numerical arrays using the custom mapping\n",
    "mapped_sequences = []\n",
    "for sequence in merged_sequences:\n",
    "    mapped_sequence = [mapping[aa] for aa in sequence]\n",
    "    mapped_sequences.append(mapped_sequence)\n",
    "\n",
    "print(\"Total number of sequences:\" ,len(mapped_sequences))\n",
    "print(\"First mapped sequence:\",mapped_sequences[0])\n",
    "print(\"Length of each sequence:\", len(mapped_sequences[0]))\n",
    "print(len(merged_labels))\n",
    "\n",
    "\n",
    "# Save the numerical sequences and labels to a new fasta-like file with numerical representations\n",
    "output_file = \"Mapped.fasta\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    for i, (mapped_sequence, label) in enumerate(zip(mapped_sequences, merged_labels)):\n",
    "        file.write(f\"Label: {label}\\n\")\n",
    "        file.write(\"Sequence: \")\n",
    "        file.write(\" \".join(map(str, mapped_sequence)))  \n",
    "        file.write(\"\\n\")\n",
    "\n",
    "print(f\"Numeric sequences and labels saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16a3fe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 6405\n",
      "Validation dataset size: 800\n",
      "Test dataset size: 802\n",
      "Sample Sequence Tensor:\n",
      "tensor([-3.6600,  2.3000, -4.8100,  0.0000,  0.0000, -4.6800, -3.5000, -1.0100,\n",
      "        -4.6800, -3.5000, -4.8100, -3.5000, -3.5000, -0.2100, -4.8100, -4.8100,\n",
      "        -1.2300,  1.7400,  1.7400,  1.5200,  0.0000, -3.5000,  1.3600, -1.0100,\n",
      "        -6.0400,  3.8800, -4.8100,  2.1100, -6.0400,  0.7500,  1.7400,  0.0000,\n",
      "        -4.8100, -1.2300,  0.7800, -3.5000, -6.0400,  1.5200, -1.0100,  0.0000,\n",
      "         2.3000,  1.7400,  0.7800,  3.8800,  0.7500,  1.7400,  3.8800,  0.9600,\n",
      "        -6.0400, -0.2100,  0.0000,  3.8800, -3.5000, -4.8100,  3.8800,  1.7400,\n",
      "        -3.5000,  0.0000,  0.7500,  0.7800,  2.3000,  2.3000,  2.3000,  3.8800,\n",
      "         3.8800, -4.6800, -4.8100, -3.5000,  1.7400,  2.3000, -1.2300,  0.9600,\n",
      "         2.1100, -4.6500,  2.1100,  1.5200,  3.8800, -3.5000, -0.2100,  1.5200,\n",
      "         0.0000, -4.6800,  2.3000,  0.7800,  2.1100,  0.0000,  0.9600,  0.7500,\n",
      "         0.0000,  0.7500,  1.5200,  0.7500, -0.2100, -0.2100,  1.7400,  1.3600,\n",
      "        -3.6600,  0.9600,  1.3600, -4.6800, -3.5000, -3.3200,  0.9600,  1.3600,\n",
      "         2.3000, -4.6800, -0.2100, -1.2300, -4.8100, -0.2100,  1.5200, -3.5000,\n",
      "        -3.3200, -0.2100,  1.7400,  1.5200, -6.0400,  1.5200, -4.6500, -4.6800,\n",
      "        -3.5000, -1.2300,  1.3600,  3.8800, -6.0400,  2.1100,  0.9600,  0.7800,\n",
      "        -0.2100,  3.8800, -1.0100,  0.7500, -3.5000,  0.0000,  1.5200,  0.9600,\n",
      "        -4.8100, -0.2100, -1.0100, -0.2100,  0.0000,  0.0000,  1.7400,  3.8800,\n",
      "        -4.6800,  0.7500,  1.3600, -3.5000, -3.5000,  1.7400, -4.6800, -4.8100,\n",
      "         3.8800, -4.6800, -3.3200,  2.3000,  0.9600,  2.3000, -3.5000,  3.8800,\n",
      "         1.3600, -4.6500,  0.9600, -1.0100,  0.9600,  0.7800,  0.0000, -4.8100,\n",
      "         0.7800,  3.8800,  1.5200,  0.9600, -4.6500, -0.2100,  3.8800, -4.8100,\n",
      "         0.0000, -1.2300, -1.0100,  0.7800,  1.5200, -3.6600, -3.5000, -3.3200,\n",
      "         0.0000,  3.8800,  0.7800,  3.8800,  2.3000, -4.8100,  0.0000, -6.0400,\n",
      "         0.0000,  1.7400, -4.6800,  3.8800, -1.0100, -3.6600,  2.3000,  0.9600,\n",
      "         3.8800, -3.6600,  1.5200,  0.9600, -1.2300, -1.0100, -4.6800, -4.8100,\n",
      "        -6.0400,  0.9600, -1.0100,  0.0000,  0.7500, -0.2100,  0.0000,  0.9600,\n",
      "        -1.0100, -4.6800,  0.0000,  1.5200, -4.6800,  0.7500,  0.9600,  0.7800,\n",
      "         3.8800,  3.8800,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000])\n",
      "Tensor shape: torch.Size([500])\n",
      "First label tensor: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "with open(\"Mapped.fasta\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "dataset = ProteinDataset(mapped_sequences, merged_labels)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "print('Train dataset size:', len(train_dataset)) \n",
    "print('Validation dataset size:', len(val_dataset)) \n",
    "print('Test dataset size:', len(test_dataset))\n",
    "\n",
    "for sequence_tensor, label_tensor in train_loader:\n",
    "    print(\"Sample Sequence Tensor:\")\n",
    "    print(sequence_tensor[0])  # Printing the first tensor in the batch\n",
    "    print(\"Tensor shape:\",sequence_tensor[0].shape)\n",
    "    print(\"First label tensor:\",label_tensor[0])\n",
    "\n",
    "    break  # Stop after printing one batch to avoid excessive output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "573dc20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_length=500,classes=1):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        #First layer\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "        \n",
    "        #Second layer\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5,padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        \n",
    "        #Third layer\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5,padding=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128*(input_length-4), 256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout4 = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, classes)\n",
    "        \n",
    "     \n",
    "\n",
    "    def forward(self, input):\n",
    "        # Apply the convolutional layers\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.dropout1(output)\n",
    "\n",
    " \n",
    "\n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.dropout2(output)\n",
    "\n",
    " \n",
    "\n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        output = self.dropout3(output)\n",
    "        \n",
    "        output = output.view(output.size(0), -1)\n",
    "        \n",
    "        output = self.fc1(output)\n",
    "        output = self.relu4(output)\n",
    "        output = self.dropout4(output)\n",
    "        output = self.fc2(output)\n",
    "        \n",
    "        # Apply sigmoid activation to the output of the last fully connected layer\n",
    "        output = torch.sigmoid(output)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a55d90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.602489080795875\n",
      "Epoch 2/10, Loss: 0.5270415439055516\n",
      "Epoch 3/10, Loss: 0.4690387106858767\n",
      "Epoch 4/10, Loss: 0.4158904355305892\n",
      "Epoch 5/10, Loss: 0.349886289697427\n",
      "Epoch 6/10, Loss: 0.3186469362332271\n",
      "Epoch 7/10, Loss: 0.2640031266670961\n",
      "Epoch 8/10, Loss: 0.24255441083357884\n",
      "Epoch 9/10, Loss: 0.20016167301398058\n",
      "Epoch 10/10, Loss: 0.18026011609114134\n",
      "Validation Accuracy: 0.87625, Validation MCC: 0.7531219989904653\n",
      "Test Accuracy: 0.8678304239401496, Test MCC: 0.7357530806873664\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "# Loss and optimizer functions\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 4. Train the Model\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for sequence_tensor, label_tensor in train_loader:\n",
    "        sequence_tensor, label_tensor = sequence_tensor.to(device), label_tensor.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(sequence_tensor.unsqueeze(1))  # Add a channel dimension for Conv1d\n",
    "        loss = criterion(outputs, label_tensor.unsqueeze(1))  # Add a channel dimension for BCELoss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print average loss for each epoch\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "    \n",
    "def evaluate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    true_positives, true_negatives, false_positives, false_negatives = 0, 0, 0, 0\n",
    "    all_predicted_labels = []  # Initialize the list\n",
    "    all_true_labels = []  # Initialize the list\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for sequence_tensor, label_tensor in data_loader:\n",
    "            sequence_tensor, label_tensor = sequence_tensor.to(device), label_tensor.to(device)\n",
    "\n",
    "            outputs = model(sequence_tensor.unsqueeze(1))\n",
    "            predicted_labels = outputs >= 0.5\n",
    "\n",
    "            correct_predictions += (predicted_labels == label_tensor.unsqueeze(1)).sum().item()\n",
    "            total_samples += label_tensor.size(0)\n",
    "\n",
    "            # Calculate true positives, true negatives, false positives, and false negatives for this batch\n",
    "            true_positives += ((predicted_labels == 1) & (label_tensor.unsqueeze(1) == 1)).sum().item()\n",
    "            true_negatives += ((predicted_labels == 0) & (label_tensor.unsqueeze(1) == 0)).sum().item()\n",
    "            false_positives += ((predicted_labels == 1) & (label_tensor.unsqueeze(1) == 0)).sum().item()\n",
    "            false_negatives += ((predicted_labels == 0) & (label_tensor.unsqueeze(1) == 1)).sum().item()\n",
    "\n",
    "            # Calculate MCC for this batch and store the predicted and true labels\n",
    "            all_predicted_labels.extend(predicted_labels.cpu().numpy())\n",
    "            all_true_labels.extend(label_tensor.unsqueeze(1).cpu().numpy())\n",
    "\n",
    "    accuracy = correct_predictions / total_samples\n",
    "\n",
    "    # Calculate Matthews Correlation Coefficient (MCC) using scikit-learn\n",
    "    mcc = matthews_corrcoef(all_true_labels, all_predicted_labels)\n",
    "\n",
    "    return accuracy, mcc\n",
    "\n",
    "\n",
    "# Evaluate on the validation set\n",
    "val_accuracy, val_mcc = evaluate_model(model, val_loader)\n",
    "print(f\"Validation Accuracy: {val_accuracy}, Validation MCC: {val_mcc}\")\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_accuracy, test_mcc = evaluate_model(model, test_loader)\n",
    "print(f\"Test Accuracy: {test_accuracy}, Test MCC: {test_mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb154570",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270778e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
