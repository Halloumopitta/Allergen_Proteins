{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a6fb94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, re\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.optim as optim  \n",
    "import torchvision.transforms as transforms  \n",
    "import torchvision\n",
    "from torch.utils.data import (Dataset,DataLoader)\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b99c3d",
   "metadata": {},
   "source": [
    "# Allergen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5753e377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total proteins left: 965\n",
      "Minimum length: 11\n",
      "Maximum length: 250\n",
      "Mean: 143.98341968911916\n",
      "Median: 137.0\n",
      "Mode: 134\n"
     ]
    }
   ],
   "source": [
    "#Define a class to  filter out  the unwanted proteins\n",
    "def filter_fasta(input_file, output_file, min_length, max_length):\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    filtered_proteins = []\n",
    "    filtered_lengths = []\n",
    "\n",
    "    current_protein = None\n",
    "    current_sequence = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith('>'):\n",
    "            if current_protein is not None:\n",
    "                sequence = ''.join(current_sequence)\n",
    "                sequence_length = len(sequence)\n",
    "                if min_length <= sequence_length <= max_length:\n",
    "                    filtered_proteins.append(current_protein + '\\n' + sequence)\n",
    "                    filtered_lengths.append(sequence_length)\n",
    "            current_protein = line.strip()\n",
    "            current_sequence = []\n",
    "        else:\n",
    "            current_sequence.append(line.strip())\n",
    "\n",
    "    # Check the last protein after the loop ends\n",
    "    if current_protein is not None:\n",
    "        sequence = ''.join(current_sequence)\n",
    "        sequence_length = len(sequence)\n",
    "        if min_length <= sequence_length <= max_length:\n",
    "            filtered_proteins.append(current_protein + '\\n' + sequence)\n",
    "            filtered_lengths.append(sequence_length)\n",
    "\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('\\n'.join(filtered_proteins))\n",
    "\n",
    "    # Calculate statistics\n",
    "    total_proteins = len(filtered_proteins)\n",
    "    min_length = min(filtered_lengths)\n",
    "    max_length = max(filtered_lengths)\n",
    "    mean = np.mean(filtered_lengths)\n",
    "    median= np.median(filtered_lengths)\n",
    "    mode = stats.mode(filtered_lengths)\n",
    "\n",
    "    # Plot distribution\n",
    "    plt.hist(filtered_lengths, bins=50)\n",
    "    plt.xlabel('Protein length')\n",
    "    plt.ylabel('Number of proteins')\n",
    "    plt.title('Histogram of filtered allergen proteins')\n",
    "    plt.show()\n",
    "\n",
    "    return total_proteins, min_length, max_length, mean, median, mode\n",
    "\n",
    "# Usage\n",
    "total, minimum, maximum,mean,median,mode = filter_fasta('Allergen_Proteins.fasta', 'Filtered_Allergen_Proteins.fasta', 10, 250)\n",
    "print(\"Total proteins left:\", total)\n",
    "print(\"Minimum length:\", minimum)\n",
    "print(\"Maximum length:\", maximum)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Mode:\", mode[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4257a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sequence(sequence, mapping):\n",
    "    map = [mapping[aa] for aa in sequence if aa in mapping]\n",
    "    return np.array(map)\n",
    "\n",
    "def map_fasta(input_file, mapping):\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    mapped_sequences = []\n",
    "\n",
    "    current_protein_id = None\n",
    "    current_sequence = ''\n",
    "    for line in lines:\n",
    "        if line.startswith('>'):\n",
    "            if current_protein_id and current_sequence:\n",
    "                mapped_sequence = map_sequence(current_sequence, mapping)\n",
    "                mapped_sequences.append((current_protein_id, mapped_sequence))\n",
    "            current_protein_id = line.strip()[1:]\n",
    "            current_sequence = ''\n",
    "        else:\n",
    "            current_sequence += line.strip()\n",
    "\n",
    "    # Process the last protein sequence\n",
    "    if current_protein_id and current_sequence:\n",
    "        mapped_sequence = map_sequence(current_sequence, mapping)\n",
    "        mapped_sequences.append((current_protein_id, mapped_sequence))\n",
    "\n",
    "    return mapped_sequences\n",
    "\n",
    "# Mapping of amino acids to numbers\n",
    "mapping = {\n",
    "    'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10,\n",
    "    'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19,\n",
    "    'Y': 20, 'X': 0, 'Z': 0\n",
    "}\n",
    "\n",
    "# Input FASTA file path\n",
    "input_file = 'Filtered_Allergen_Proteins.fasta'\n",
    "\n",
    "\n",
    "mapped_sequences = map_fasta(input_file, mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d96fce5",
   "metadata": {},
   "source": [
    "# Unkwown proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b539035a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2500 proteins and saved them as 'Reduced_NOT_Allergen_Proteins.fasta'.\n"
     ]
    }
   ],
   "source": [
    "input_file = 'NOT_Allergen_Proteins.fasta'\n",
    "output_file = 'Reduced_NOT_Allergen_Proteins.fasta'\n",
    "selected = 2500\n",
    "\n",
    "\n",
    "proteins = list(SeqIO.parse(input_file, 'fasta'))\n",
    "\n",
    "\n",
    "selected_proteins = random.sample(proteins, selected)\n",
    "\n",
    "# Write the selected protein records to the output file\n",
    "SeqIO.write(selected_proteins, output_file, 'fasta')\n",
    "\n",
    "print(f\"Selected {selected} proteins and saved them as '{output_file}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe0f4d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total proteins left: 1069\n",
      "Minimum length: 10\n",
      "Maximum length: 250\n",
      "Mean: 150.02245088868102\n",
      "Median: 150.0\n",
      "Mode: 156\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "total, minimum, maximum, mean,median,mode = filter_fasta('Reduced_NOT_Allergen_Proteins.fasta', 'Filtered_NOT_Allergen_Proteins.fasta', 10, 250)\n",
    "print(\"Total proteins left:\", total)\n",
    "print(\"Minimum length:\", minimum)\n",
    "print(\"Maximum length:\", maximum)\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Mode:\", mode[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da638d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert amino acid sequences to numbers\n",
    "def map_sequence(sequence, mapping):\n",
    "    map = [mapping[aa] for aa in sequence if aa in mapping]\n",
    "    return np.array(map)\n",
    "\n",
    "def map_fasta(input_file, mapping):\n",
    "    with open(input_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    mapped_sequences = []\n",
    "\n",
    "    current_protein_id = None\n",
    "    current_sequence = ''\n",
    "    for line in lines:\n",
    "        if line.startswith('>'):\n",
    "            if current_protein_id and current_sequence:\n",
    "                mapped_sequence = map_sequence(current_sequence, mapping)\n",
    "                mapped_sequences.append((current_protein_id, mapped_sequence))\n",
    "            current_protein_id = line.strip()[1:]\n",
    "            current_sequence = ''\n",
    "        else:\n",
    "            current_sequence += line.strip()\n",
    "\n",
    "    # Process the last protein sequence\n",
    "    if current_protein_id and current_sequence:\n",
    "        mapped_sequence = map_sequence(current_sequence, mapping)\n",
    "        mapped_sequences.append((current_protein_id, mapped_sequence))\n",
    "\n",
    "    return mapped_sequences\n",
    "\n",
    "# Mapping of amino acids to numbers\n",
    "mapping = {\n",
    "    'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'K': 9, 'L': 10,\n",
    "    'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19,\n",
    "    'Y': 20, 'X': 0 , 'U': 0, 'B': 0, 'J': 0, 'O': 0,'Z':0\n",
    "}\n",
    "\n",
    "# Input FASTA file path\n",
    "input_file = 'Filtered_NOT_Allergen_Proteins.fasta'\n",
    "\n",
    "\n",
    "mapped_sequences = map_fasta(input_file, mapping)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c9d5c",
   "metadata": {},
   "source": [
    "# Merge datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9dca741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of proteins: 2034\n",
      "Total number of allergen proteins: 965\n",
      "Total number of non allergen proteins: 1069\n",
      "Max length: 250\n",
      "First 5 proteins:\n",
      "Label: 0\n",
      "Sequence: MKNENLQQKNQTVSSPIVVALDYASQDAALSFVDRIDPQDCRLKVGKEMFTLFGPQFVQTLQQRGFDVFLDLKFHDIPNTVAHAVAAAADLGVWMVNVHASGGSRMMAAAKDALVPFGKDAPLLIAVTVLTSMDEEDLRGLGITVSPAEQAERLAVLTHNSGLDGVVCSAHEAQRLKQVCGQAFKLITPGIRPAGSDVGDQRRIMTPIQAQQAGVDYMVIGRPITQSSDPAQTLCDIRASLLNGIASXXX\n",
      "\n",
      "Label: 0\n",
      "Sequence: VTVYENEGTKVDFDGNLRLLLXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "\n",
      "Label: 0\n",
      "Sequence: MAAKIRQNDEVIVLAGKDKGKRGKVTKVLPNGKVFVEGVNIITKHEKPVPALGKAGGLVKKEAAIDVSNVAIFNPTTNKADRVGFRIEDGKKVRFFKSNNEIIXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "\n",
      "Label: 0\n",
      "Sequence: MAKIRPPKPKRMGRGAQRCQRCGTRDAVIQKYGLYLCRQCFREIAPTLGFRKNRXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "\n",
      "Label: 0\n",
      "Sequence: MDEKARLLRVRARLKRKKPKFLRQEWWRFPKFKNDPKWRRPKGIDSKMRLKKKGKPRSPSIGWSSPRAVRGLHPSGYEEVLVHNVKELEAIDPTRQAARIARTVGARKREAIIARAKELGIKVLNARXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sequence_padding(sequences, max_length):\n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        padding_length = max_length - len(seq)\n",
    "        padded_seq = seq + \"X\" * padding_length  # Padding with a special token, \"X\"\n",
    "        padded_sequences.append(padded_seq)\n",
    "    return padded_sequences\n",
    "\n",
    "allergen_sequences = []\n",
    "allergen_headers = []\n",
    "\n",
    "with open(\"Filtered_Allergen_Proteins.fasta\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    if line.startswith(\">\"):\n",
    "        allergen_headers.append(line.strip())\n",
    "    else:\n",
    "        allergen_sequences.append(line.strip())\n",
    "        \n",
    "\n",
    "\n",
    "non_allergen_sequences = []\n",
    "non_allergen_headers = []\n",
    "\n",
    "with open(\"Filtered_NOT_Allergen_Proteins.fasta\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    if line.startswith(\">\"):\n",
    "        non_allergen_headers.append(line.strip())\n",
    "    else:\n",
    "        non_allergen_sequences.append(line.strip())\n",
    "\n",
    "# Step 2: Create a merged dataset\n",
    "merged_sequences = allergen_sequences + non_allergen_sequences\n",
    "merged_labels = [1] * len(allergen_sequences) + [0] * len(non_allergen_sequences)\n",
    "\n",
    "# Shuffle the protein order\n",
    "merged_data = list(zip(merged_sequences, merged_labels))\n",
    "random.shuffle(merged_data)\n",
    "merged_sequences, merged_labels = zip(*merged_data)\n",
    "\n",
    "# Step 3: Determine the maximum sequence length for padding\n",
    "max_length = max(len(seq) for seq in merged_sequences)\n",
    "\n",
    "# Step 4: Apply sequence padding\n",
    "padded_sequences = sequence_padding(merged_sequences, max_length)\n",
    "\n",
    "# Step 5: Save the merged dataset with padded sequences\n",
    "with open(\"Proteins.fasta\", \"w\") as file:\n",
    "    for i in range(len(padded_sequences)):\n",
    "        file.write(\"> Label:\" + str(merged_labels[i]) + \"\\n\")\n",
    "        file.write(padded_sequences[i] + \"\\n\")\n",
    "\n",
    "# Print the total number of proteins\n",
    "total_proteins = len(padded_sequences)\n",
    "print(\"Total number of proteins:\", total_proteins)\n",
    "\n",
    "\n",
    "label_1 = sum(label == 1 for label in merged_labels)\n",
    "label_0 = sum(label == 0 for label in merged_labels)\n",
    "\n",
    "print(\"Total number of allergen proteins:\", label_1)\n",
    "print(\"Total number of non allergen proteins:\", label_0)\n",
    "print(\"Max length:\",max_length)\n",
    "# Print the first 5 proteins\n",
    "print(\"First 5 proteins:\")\n",
    "for i in range(5):\n",
    "    print(\"Label:\", merged_labels[i])\n",
    "    print(\"Sequence:\", padded_sequences[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "29a2f981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 1: 0\n",
      "Sequence 1: MKNENLQQKNQTVSSPIVVALDYASQDAALSFVDRIDPQDCRLKVGKEMFTLFGPQFVQTLQQRGFDVFLDLKFHDIPNTVAHAVAAAADLGVWMVNVHASGGSRMMAAAKDALVPFGKDAPLLIAVTVLTSMDEEDLRGLGITVSPAEQAERLAVLTHNSGLDGVVCSAHEAQRLKQVCGQAFKLITPGIRPAGSDVGDQRRIMTPIQAQQAGVDYMVIGRPITQSSDPAQTLCDIRASLLNGIASXXX\n",
      "\n",
      "Total number of sequences: 2034\n",
      "First mapped sequence: [11, 9, 12, 4, 12, 10, 14, 14, 9, 12, 14, 17, 18, 16, 16, 13, 8, 18, 18, 1, 10, 3, 20, 1, 16, 14, 3, 1, 1, 10, 16, 5, 18, 3, 15, 8, 3, 13, 14, 3, 2, 15, 10, 9, 18, 6, 9, 4, 11, 5, 17, 10, 5, 6, 13, 14, 5, 18, 14, 17, 10, 14, 14, 15, 6, 5, 3, 18, 5, 10, 3, 10, 9, 5, 7, 3, 8, 13, 12, 17, 18, 1, 7, 1, 18, 1, 1, 1, 1, 3, 10, 6, 18, 19, 11, 18, 12, 18, 7, 1, 16, 6, 6, 16, 15, 11, 11, 1, 1, 1, 9, 3, 1, 10, 18, 13, 5, 6, 9, 3, 1, 13, 10, 10, 8, 1, 18, 17, 18, 10, 17, 16, 11, 3, 4, 4, 3, 10, 15, 6, 10, 6, 8, 17, 18, 16, 13, 1, 4, 14, 1, 4, 15, 10, 1, 18, 10, 17, 7, 12, 16, 6, 10, 3, 6, 18, 18, 2, 16, 1, 7, 4, 1, 14, 15, 10, 9, 14, 18, 2, 6, 14, 1, 5, 9, 10, 8, 17, 13, 6, 8, 15, 13, 1, 6, 16, 3, 18, 6, 3, 14, 15, 15, 8, 11, 17, 13, 8, 14, 1, 14, 14, 1, 6, 18, 3, 20, 11, 18, 8, 6, 15, 13, 8, 17, 14, 16, 16, 3, 13, 1, 14, 17, 10, 2, 3, 8, 15, 1, 16, 10, 10, 12, 6, 8, 1, 16, 0, 0, 0]\n",
      "Length of each sequence: 250\n",
      "2034\n",
      "Numeric sequences and labels saved to Mapped.fasta\n"
     ]
    }
   ],
   "source": [
    "################################################################################################################################\n",
    "\n",
    "#Create a class that takes the encoded sequences and labels to split later for train,val and test\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        \n",
    "        sequence_tensor = torch.tensor(sequence, dtype=torch.float)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "        return sequence_tensor, label_tensor\n",
    "\n",
    "    \n",
    "################################################################################################################################\n",
    "\n",
    "################################################################################################################################\n",
    "# Load the merged dataset with padded sequences and verify it works by printing the first sequence\n",
    "merged_sequences = []\n",
    "merged_labels = []\n",
    "\n",
    "with open(\"Proteins.fasta\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "for i in range(0, len(lines),2):\n",
    "    sequence = lines[i+1].strip() #check every odd line and strip any whitespace\n",
    "    label = int(lines[i].split(\":\")[1]) #check every even line\n",
    "    merged_sequences.append(sequence)\n",
    "    merged_labels.append(label)\n",
    "    \n",
    "for i in range(1):\n",
    "    print(f\"Label {i+1}: {merged_labels[i]}\")\n",
    "    print(f\"Sequence {i+1}: {merged_sequences[i]}\")\n",
    "    print()\n",
    "\n",
    "################################################################################################################################\n",
    "#Map sequences to numbers again and save the file\n",
    "mapping= {\n",
    "    'A': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7,\n",
    "    'I': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14,\n",
    "    'R': 15, 'S': 16, 'T': 17, 'V': 18, 'W': 19, 'Y': 20,\n",
    "    'X': 0, 'U': 0, 'B': 0, 'J': 0, 'O': 0, 'Z': 0\n",
    "}\n",
    "\n",
    "# Convert all sequences to numerical arrays using the custom mapping\n",
    "# Assuming you have already loaded the merged_sequences list and defined the custom mapping\n",
    "\n",
    "# Convert all sequences to numerical arrays using the custom mapping\n",
    "mapped_sequences = []\n",
    "for sequence in merged_sequences:\n",
    "    mapped_sequence = [mapping[aa] for aa in sequence]\n",
    "    mapped_sequences.append(mapped_sequence)\n",
    "\n",
    "print(\"Total number of sequences:\" ,len(mapped_sequences))\n",
    "print(\"First mapped sequence:\",mapped_sequences[0])\n",
    "print(\"Length of each sequence:\", len(mapped_sequences[0]))\n",
    "print(len(merged_labels))\n",
    "\n",
    "\n",
    "# Save the numerical sequences and labels to a new fasta-like file with numerical representations\n",
    "output_file = \"Mapped.fasta\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    for i, (mapped_sequence, label) in enumerate(zip(mapped_sequences, merged_labels)):\n",
    "        file.write(f\"Label: {label}\\n\")\n",
    "        file.write(\"Sequence: \")\n",
    "        file.write(\" \".join(map(str, mapped_sequence)))  \n",
    "        file.write(\"\\n\")\n",
    "\n",
    "print(f\"Numeric sequences and labels saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "16a3fe98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 1627\n",
      "Validation dataset size: 203\n",
      "Test dataset size: 204\n",
      "Sample Sequence Tensor:\n",
      "tensor([11.,  4.,  1., 13.,  6., 18., 10., 10., 18., 11.,  6., 18., 16.,  6.,\n",
      "        16.,  6.,  9., 16., 17., 18.,  6.,  1., 10., 10.,  1., 16.,  9., 10.,\n",
      "         6., 19.,  9.,  5., 20.,  3.,  1.,  3.,  3., 20.,  7., 16.,  4.,  4.,\n",
      "        12., 15.,  8.,  9., 11.,  1.,  9.,  6., 18., 13., 10., 16.,  3., 14.,\n",
      "         3., 15.,  8., 13., 19., 10.,  2., 17., 10.,  7.,  3.,  8., 10., 10.,\n",
      "        15.,  3., 18.,  1., 10.,  6., 14., 13., 18., 18., 10.,  1.,  2., 16.,\n",
      "         1., 10.,  9.,  9., 17., 20., 15.,  3.,  8., 10.,  8., 15.,  6.,  6.,\n",
      "        16.,  3.,  1., 13., 10.,  9., 16.,  3.,  3., 16.,  1.,  9.,  4., 13.,\n",
      "        10.,  1.,  6.,  6.,  9., 10., 10., 18., 18., 20., 10.,  2.,  6., 16.,\n",
      "         5.,  3.,  8.,  8., 20.,  6., 15., 10., 10., 14., 15.,  9.,  6.,  7.,\n",
      "         5., 11., 13., 13.,  4., 10., 10., 14., 16., 14.,  5., 16.,  8., 10.,\n",
      "         4., 13., 13., 16.,  1., 13.,  4., 12.,  5.,  8., 14., 18., 16., 18.,\n",
      "         3.,  9., 16., 10., 13.,  4.,  8., 17.,  1.,  1., 18., 11.,  4.,  1.,\n",
      "        10.,  9.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])\n",
      "torch.Size([250])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "with open(\"Mapped.fasta\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "dataset = ProteinDataset(mapped_sequences, merged_labels)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "print('Train dataset size:', len(train_dataset)) \n",
    "print('Validation dataset size:', len(val_dataset)) \n",
    "print('Test dataset size:', len(test_dataset))\n",
    "\n",
    "for sequence_tensor, label_tensor in train_loader:\n",
    "    print(\"Sample Sequence Tensor:\")\n",
    "    print(sequence_tensor[0])  # Printing the first tensor in the batch\n",
    "    print(sequence_tensor[0].shape)\n",
    "    print(label_tensor[0])\n",
    "\n",
    "    break  # Stop after printing one batch to avoid excessive output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3716779d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5 #complete passess over the data set\n",
    "classes = 2 #allergen or non-allergen\n",
    "batch_size = 100 #data must be loaded in batches for more efficient training (high batch size can lead to memory overload)\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2ab91098",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, classes=2):\n",
    "        super(ConvNet, self).__init__()\n",
    "\n",
    " \n",
    "\n",
    "        # First layer\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(0.2)\n",
    "\n",
    " \n",
    "\n",
    "        # Second layer\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "\n",
    " \n",
    "\n",
    "        # Third layer\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "\n",
    " \n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * (input_length - 4), 256)  # Update input_length according to your data size\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout4 = nn.Dropout(0.2)\n",
    "\n",
    " \n",
    "\n",
    "        self.fc2 = nn.Linear(256, classes)\n",
    "\n",
    " \n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(input.size(0), 1, -1)\n",
    "\n",
    " \n",
    "\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "        output = self.dropout1(output)\n",
    "\n",
    " \n",
    "\n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.dropout2(output)\n",
    "\n",
    " \n",
    "\n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "        output = self.dropout3(output)\n",
    "\n",
    " \n",
    "\n",
    "        # Flatten the output\n",
    "        output = output.view(output.size(0), -1)\n",
    "\n",
    " \n",
    "\n",
    "        output = self.fc1(output)\n",
    "        output = self.relu4(output)\n",
    "        output = self.dropout4(output)\n",
    "\n",
    " \n",
    "\n",
    "        output = self.fc2(output)\n",
    "\n",
    " \n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d81fe3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas\\AppData\\Local\\Temp/ipykernel_23164/1310814860.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sequence_tensor = torch.tensor(sequence, dtype=torch.float)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (100x3584 and 31488x256)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23164/3962178307.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mtrain_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23164/1589228071.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (100x3584 and 31488x256)"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = ConvNet(classes=2).to(device)\n",
    "\n",
    "# Loss and optimizer functions\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Lists to store training and validation losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Function to evaluate the model on the validation set\n",
    "def evaluate_model(loader, model):\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in loader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            loss = criterion(output, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predictions = output.max(1)\n",
    "            num_correct += (predictions == labels).sum().item()\n",
    "            num_total += predictions.size(0)\n",
    "           \n",
    "            \n",
    "    model.train()  # Set the model back to training mode\n",
    "    accuracy = 100.0 * num_correct / num_total\n",
    "    return total_loss, accuracy\n",
    "\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_index, (train_data, train_labels) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        train_data = train_data.to(device)\n",
    "        train_labels = train_labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        train_output = model(train_data)\n",
    "        loss = criterion(train_output, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Calculate and store the average training loss for this epoch\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    print(f\"For epoch {epoch+1} the training loss is {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Evaluate the model on the validation set and store the validation loss\n",
    "    val_loss, val_accuracy = evaluate_model(val_loader, model)\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    print(f\"The validation loss is {val_losses[-1]:.4f} and the validation accuracy is {val_accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "# Plot the Train and Validation losses\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Losses\")\n",
    "plt.title(\"Protein classification\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573dc20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37884d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
